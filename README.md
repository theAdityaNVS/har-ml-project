# Human Activity Recognition using Machine Learning - Project

Aims to Recognise various Human Activities through Machine Learning Algorithms and input is given as video file

## About

1. LSTM model from data set given under https://github.com/stuarteiffert/RNN-for-Human-Activity-Recognition-using-2D-Pose-Input

2. Using Detectron2 for pose estimation and the dataset is mapped to Detectron2 output format for training our LSTM model. 

3. Currently the Model classifies the action into 6 categories
- "JUMPING",
- "HIGH JUMP",
- "PUNCHING",
- "HANDS UP",
- "WAVING HAND",
- "HANDS TOGETHER"

4. Using NgRok for webpage output and interaction page.

## References

- Reference and credits from [learnOpen CV](https://learnopencv.com/human-action-recognition-using-detectron2-and-lstm/).
- Original dataset is created using [OpenPose](https://github.com/CMU-Perceptual-Computing-Lab/openpose)